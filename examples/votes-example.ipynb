{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a34e0a91-86a6-4d8d-9622-45cbbcc4f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7656274-8a61-43e6-85b4-ad3cccce2177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from simsity.service import Service\n",
    "from simsity.datasets import fetch_voters\n",
    "from simsity.indexer import PyNNDescentIndexer\n",
    "\n",
    "# Don't forget to pip install dirty_cat\n",
    "from dirty_cat import GapEncoder\n",
    "\n",
    "df = fetch_voters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c0812e2-acd7-49e1-a799-19ad64e7e396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<simsity.service.Service at 0x7ffb4844e9d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = GapEncoder()\n",
    "\n",
    "service = Service(\n",
    "    indexer=PyNNDescentIndexer(metric=\"euclidean\", n_jobs=6),\n",
    "    encoder=encoder\n",
    ")\n",
    "\n",
    "# Index the datapoints\n",
    "service.train_from_dataf(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2613e6c-e578-4324-9457-448d252dc54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name            | suburb     |   postcode |\n",
      "|:----------------|:-----------|-----------:|\n",
      "| heather stewart | concord    |      28027 |\n",
      "| darlene smith   | lincolnton |      28092 |\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "def generate_pair(service, n_consider=10):\n",
    "    idx = random.randint(0, len(service.storage) - 1)\n",
    "    query = service.storage[idx]\n",
    "    df_out = service.query(**query, n_neighbors=n_consider, out='dataframe')\n",
    "    return df_out.drop(columns='dist').sample(2)\n",
    "\n",
    "print(generate_pair(service).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fff60ef-9912-4bcd-8b04-25e1293d9beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82c4be5359e4de792f367266d334a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 examples annotated, 201 examples left')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee5b20de5004c3a8f64bb4c161ddc3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='similar', style=ButtonStyle()), Button(description='not similar', style=Butâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6854e7f279fa40bc96cf0f6c897f35b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Don't forget to pip install pigeon-jupyter\n",
    "from pigeon import annotate\n",
    "\n",
    "annotations = annotate(\n",
    "  (generate_pair(service, n_consider=3) for x in range(200)),\n",
    "  options=['similar', 'not similar'],\n",
    "  display_fn=display\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a6ce37-18ad-44b8-8ae5-3838f7690747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annot_to_dataf(annotations):\n",
    "    data = []\n",
    "    for a in annotations:\n",
    "        d1, d2 = a[0].to_dict(orient='records')\n",
    "        d1 = {f'{k}_1': v for k, v in d1.items()}\n",
    "        d2 = {f'{k}_2': v for k, v in d2.items()}\n",
    "        data.append({**d1, **d2, 'label': a[1]})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def annot_to_X_y(annotations, encoder):\n",
    "    data1 = []\n",
    "    data2 = []\n",
    "    ys = []\n",
    "    for a in annotations:\n",
    "        d1, d2 = a[0].to_dict(orient='records')\n",
    "        data1.append(d1)\n",
    "        data2.append(d2)\n",
    "        ys.append(a[1])\n",
    "    X1 = encoder.transform(pd.DataFrame(data1))\n",
    "    X2 = encoder.transform(pd.DataFrame(data2))\n",
    "    return X1, X2, ys\n",
    "\n",
    "X1, X2, y = annot_to_X_y(annotations, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f72c9b12-2f61-4469-b6ea-326d6f556284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name_1          | suburb_1      | postcode_1   | name_2          | suburb_2      | postcode_2   | label       |\n",
      "|:----------------|:--------------|:-------------|:----------------|:--------------|:-------------|:------------|\n",
      "| stacey gore     | maggie avlley | 287s1        | namcy cruse     | rocky mount   | 27871        | not similar |\n",
      "| kenneth reed    | winston salem | 27101        | bessie smith    | winston salem | 27107        | not similar |\n",
      "| angela franklin | canton        | 28716        | angla franklin  | canton        | 287|6        | similar     |\n",
      "| carla macartney | charlotte     | 28227        | caria macartney | charlotte     | 28220        | similar     |\n",
      "| maryann ca5h    | waxha         | 28173        | jaime cable     | canton        | 28716        | not similar |\n"
     ]
    }
   ],
   "source": [
    "print(annot_to_dataf(annotations).head(5).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9114f49a-b269-4a71-8bdc-df10161fde3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_difference = X1 - X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ef06988-9b10-4968-98e5-162d5066ddcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7623762376237624"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pred = LogisticRegression().fit(X_difference, y).predict(X_difference)\n",
    "np.mean(pred == y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
